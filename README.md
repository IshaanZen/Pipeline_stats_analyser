# ğŸš€ Databricks Pipeline Stats Analyser

A smart, business-friendly dashboard that converts complex Databricks pipeline performance data into easy-to-understand insights for managers, project stakeholders, and non-technical decision makers.

This project supports **two types of inputs**:

* ğŸ“Š **Structured Data (CSV / JSON)** â€“ Traditional pipeline metrics files
* ğŸ“¸ **Pipeline Screenshots (Images)** â€“ UI screenshots from Databricks Cluster / Spark UI

Behind the scenes, the app uses AI to:

* Extract metrics (even from images)
* Summarise pipeline health
* Provide plain-English explanations for business use

---

## âœ¨ Key Features

### âœ… Structured Data Mode

* Upload CSV or JSON with pipeline metrics
* Interactive filters by pipeline
* Visual Charts

  * CPU Utilisation per run
  * Memory Usage per run
* Aggregate statistics

  * Average runtime
  * Average CPU & Memory usage
* AI-generated explanations of pipeline performance

### âœ… Image Mode (AI Vision-powered)

* Upload two Databricks screenshots:

  1. Cluster / Driver Stats
  2. Only Executor Nodes Stats
* AI extracts approximate metrics
* Converts visual graphs into structured JSON
* Generates a business-friendly performance summary

---

## ğŸ§  Who is this for?

* Project Managers
* Business Stakeholders
* Analysts
* Non-technical Leadership
* Data Engineering Teams presenting reports

---

## ğŸ› ï¸ Tech Stack

* **Streamlit** â€“ Web UI framework
* **Python** â€“ Core logic
* **OpenRouter API** â€“ AI layer (Vision + Text)
* **Pandas** â€“ Data processing
* **dotenv** â€“ Secure configuration handling

---

## ğŸ“ Project Structure

```
pipeline-stats-analyser/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_data.json
â”œâ”€â”€ .env                # Not committed to Git
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ” Environment Setup

Create a `.env` file in the root folder:

```
OPENROUTER_API_KEY=your_api_key_here
```

This file is ignored using `.gitignore` to keep your key safe.

---

## â–¶ï¸ How to Run Locally

### 1. Install dependencies

```
pip install -r requirements.txt
```

If you donâ€™t have a requirements file yet:

```
pip install streamlit pandas python-dotenv openai
```

### 2. Start the app

```
streamlit run app.py
```

Open your browser at:

```
http://localhost:8501
```

---

## ğŸ“Š Example Use Cases

* Weekly pipeline performance review meeting
* Client presentation of Databricks job efficiency
* Quick troubleshooting overview for management
* Visual-to-report automation

---

## ğŸ”® Future Enhancements

* Export report as PDF
* Slack / Email alerts
* Historical trend comparison
* Auto anomaly detection
* Integration with Databricks API

---

## ğŸ‘¨â€ğŸ’» Author

Built with ğŸ’™ by a Databricks Data Engineering Intern
for real-world business enablement and performance clarity.

---

## â­ Star the repo if you find it useful!

This project aims to bridge the gap between deep technical systems and business understanding.
